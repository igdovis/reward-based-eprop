# Reward-based-e-prop
## Reward based e-prop implementation for bachelor thesis

Experiments were done in google colab and on a local laptop.

Laptop specifications: 16GB RAM, Nvidia GeForce RTX 3060 Laptop GPU, AMD RYZEN 7 5800H CPU

`seq_length` variable of RSNN computation steps highly influences training time.

Two types of networks present: a network solely from LIF neurons and solely from ALIF.

The models are different, but the actor-critic algorithm to optimize the policy is the same for both of them.




